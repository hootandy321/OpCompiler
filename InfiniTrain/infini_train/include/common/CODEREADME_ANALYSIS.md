# 目录: include/common 架构全景

## 1. 子系统职责

`include/common` 目录是 InfiniTrain 训练框架的 **硬件抽象层（HAL）** 和 **通用基础设施库**，为上层训练内核提供跨平台（CPU/CUDA）的类型安全转换、数学运算原语和错误处理机制。该层通过统一的接口设计屏蔽了底层硬件差异（CPU vs GPU），支持混合精度训练（fp32/fp16/bf16）所需的类型转换和计算操作，同时提供 CUDA 生态的集成能力（CUBLAS/NCCL）。它在整个架构中扮演"承上启下"的角色：向上为算子内核提供高性能原语，向下直接与 CUDA Runtime、Driver API 和 C++ 标准库交互。

## 2. 模块导航

* **cpu (CPU 后端通用工具库)**
    * *功能*: 提供轻量级的 CPU 端类型安全转换模板，采用 C++ 完美转发机制实现跨类型值转换，保留左值/右值类别和 const/volatile 限定符。当前专注于标准 C++ 类型转换，低精度浮点（fp16/bf16）支持标记为待扩展。
    * *职责*: 为 CPU 后端的数据预处理、张量操作和类型转换提供编译期优化的零开销抽象层，确保类型安全的同时避免运行时性能损耗。

* **cuda (CUDA 基础设施与内核原语库)**
    * *功能*: 实现 CUDA 生态的完整基础设施栈，包括（1）统一的错误处理宏系统，覆盖 CUDA Runtime、Driver API、CUBLAS 和 NCCL；（2）类型泛化的数学运算库，通过 if constexpr 为 half/bf16/float/double 选择最优硬件指令；（3）向量化原子操作优化，利用 __half2/__nv_bfloat162 打包提升原子加法性能。
    * *职责*: 为 GPU 训练内核提供高性能计算原语和错误安全保障，通过编译期分支和硬件内在函数（intrinsics）最大化 CUDA 计算效率，同时通过统一错误检查机制简化调试和故障定位。

* **common.h (平台无关的通用宏定义)**
    * *功能*: 定义跨 CPU/CUDA 使用的工具宏（CEIL_DIV 除法向上取整、LOG_LOC 日志位置记录、LOG_UNSUPPORTED_DTYPE 不支持数据类型的错误报告）和辅助函数（ComputeStrides 张量步长计算）。
    * *职责*: 提供整个 InfiniTrain 框架共享的基础工具集合，确保代码一致性和错误处理的标准化。

## 3. 架构逻辑图解

```
┌─────────────────────────────────────────────────────────────┐
│                    上层训练算子内核层                          │
│              (InfiniTrain 算子实现，如 GEMM、卷积等)           │
└──────────────────────────┬──────────────────────────────────┘
                           │ 调用
                           ▼
┌─────────────────────────────────────────────────────────────┐
│               include/common (硬件抽象层 HAL)                 │
├─────────────────────────────────────────────────────────────┤
│  common.h (平台无关工具)                                      │
│  ├─ CEIL_DIV: 除法向上取整宏                                  │
│  ├─ LOG_LOC: 带位置的日志记录                                │
│  ├─ LOG_UNSUPPORTED_DTYPE: 数据类型错误检查                  │
│  └─ ComputeStrides: 张量步长计算                             │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  ┌─────────────────┐          ┌─────────────────────────┐   │
│  │   cpu/          │          │   cuda/                 │   │
│  │  (CPU 后端)     │          │  (CUDA 后端)            │   │
│  ├─────────────────┤          ├─────────────────────────┤   │
│  │ Cast<>()        │          │ 错误处理宏系统:          │   │
│  │ ├─ 完美转发     │          │ ├─ CUDA_CHECK           │   │
│  │ ├─ 类型安全     │          │ ├─ CUBLAS_CHECK         │   │
│  │ └─ 编译期优化   │          │ ├─ CUDA_DRIVER_CHECK    │   │
│  │                 │          │ └─ NCCL_CHECK           │   │
│  │ TODO:           │          │                         │   │
│  │ fp16/bf16 支持  │          │ 类型转换系统:            │   │
│  └─────────────────┘          │ ├─ Cast<>()             │   │
│                                │ ├─ 硬件内在函数优化      │   │
│                                │ └─ if constexpr 分支    │   │
│                                │                         │   │
│                                │ 数学运算库:              │   │
│                                │ ├─ 基础运算(+-*/)       │   │
│                                │ ├─ 三角函数(sin/cos)    │   │
│                                │ ├─ 激活函数(tanh/sigmoid)│   │
│                                │ ├─ 特殊函数(exp/log/pow)│   │
│                                │ └─ FMA 融合乘加         │   │
│                                │                         │   │
│                                │ 原子操作优化:            │   │
│                                │ ├─ fastAtomicAdd        │   │
│                                │ ├─ __half2 向量化       │   │
│                                │ └─ 地址对齐检查         │   │
│                                └─────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
                           │ 依赖
                           ▼
┌─────────────────────────────────────────────────────────────┐
│                    底层系统库和硬件                           │
├───────────────────┬──────────────────────────────────────────┤
│ CPU 路径          │ CUDA 路径                                │
│ ├─ C++ STL        │ ├─ CUDA Runtime API                     │
│ └─ 编译器优化     │ ├─ CUDA Driver API                      │
│                   │ ├─ CUBLAS 库                            │
│                   │ ├─ NCCL 库 (可选)                       │
│                   │ ├─ glog 日志库                          │
│                   │ └─ 硬件内在函数 (__hadd, __hfma 等)     │
└───────────────────┴──────────────────────────────────────────┘
```

**数据流与交互关系**：

1. **上层算子调用流程**：
   * 训练算子内核根据执行硬件选择后端路径，在 GPU 设备函数中调用 `cuda/` 提供的数学运算（如 `Sigmoid<__half>`），在 CPU 代码中调用 `cpu/` 的 `Cast<>` 进行类型转换。
   * 所有路径共享 `common.h` 中的工具宏和 `ComputeStrides` 函数，确保张量形状计算的一致性。

2. **跨后端类型转换链路**：
   * CPU 后端：`Cast<DST>(SRC&&)` 使用 C 风格转换 `(DST)` 执行通用类型转换，通过完美转发保留值类别，编译期 static_assert 禁止返回引用。
   * CUDA 后端：`Cast<DST>(SRC&&)` 采用 `if constexpr` 在编译期分发，half/bf16 使用专用硬件指令（`__half2float`/`__float2half`），其他类型回退到 `static_cast`，同样保留值类别并禁止引用返回。
   * 扩展差异：CUDA 已完整支持 fp16/bf16 硬件加速，CPU 尚未实现（TODO 状态）。

3. **CUDA 错误处理与日志集成**：
   * 所有 CUDA API 调用（cudaMalloc、cublasCreate、ncclAllReduce 等）必须通过对应的 `_CHECK` 宏包裹。
   * 宏展开时调用 `LOG(FATAL)` 输出错误字符串、文件名和行号到 glog，实现统一的错误报告和故障定位。
   * 使用 `do { ... } while(0)` 惯用法确保宏在 if-else 语句中的语法正确性。

4. **GPU 内核性能优化路径**：
   * **数学运算**：half/bf16 类型直接使用 CUDA 内在函数（`__hadd`/`__hmul`/`__hfma`）避免 float 转换开销；float/double 使用 `__expf`/`tanhf` 等快速版本；所有分支通过 `if constexpr` 在编译期选定。
   * **原子操作**：`fastAtomicAdd` 检查地址对齐，非边界情况下构造 `__half2` 或 `__nv_bfloat162` 向量执行 32 位原子操作（性能约 2 倍于 16 位标量原子操作），边界条件回退到标量路径。
   * **融合乘加**：half 使用 `__hfma` 单指令，bf16 转换到 float 后使用 `__fmaf_rn`（round-to-nearest），确保精度与性能平衡。

5. **混合精度训练支持**：
   * 在前向传播时，权重可能以 fp16 存储，通过 `Cast<float>(__half)` 转换到 float32 进行累加。
   * 梯度更新时，本地梯度通过 `fastAtomicAdd` 累加到全局梯度张量，使用向量化优化减少内存事务。
   * 激活函数（如 Sigmoid/Tanh）直接在低精度类型上计算，避免类型转换开销。

**设计原则与权衡**：

* **零开销抽象**：CPU 和 CUDA 后端均采用模板元编程和编译期优化，所有函数内联展开，无运行时分支或虚函数开销。
* **类型安全**：两个后端的 `Cast<>` 均在编译期检查禁止返回引用，防止悬空引用；CUDA 的数学运算通过模板特化确保类型匹配。
* **硬件亲和性**：CUDA 后端充分利用硬件特性（向量化原子操作、内在函数、FMA 指令），CPU 后端依赖编译器优化和 STL。
* **渐进式扩展**：CPU 后端的 fp16/bf16 支持标记为 TODO，表明当前设计优先 CUDA 路径，未来可对称扩展。

**依赖关系图**：

```
common.h
  ├─ glog/logging.h (日志库)
  └─ datatype.h (InfiniTrain 数据类型定义)

cpu/common_cpu.h
  └─ (仅依赖 C++ STL，无外部依赖)

cuda/common_cuda.h
  ├─ cuda_runtime.h (CUDA Runtime API)
  ├─ cublas_v2.h (CUBLAS 库)
  ├─ nccl.h (条件编译，USE_NCCL 时启用)
  └─ glog/logging.h

cuda/kernel_helper.cuh
  ├─ cuda_runtime.h
  ├─ cuda_fp16.h (__half 类型)
  ├─ cuda_bf16.h (nv_bfloat16 类型)
  └─ cmath (std::pow, std::exp 等)
```

**关键性能指标**（基于文档描述）：

* CPU Cast 转换：O(1) 时间复杂度，完全内联，零额外内存分配。
* CUDA 数学运算：half/bf16 使用单硬件指令，避免类型转换；FMA 操作延迟约 1 个周期（取决于 GPU 架构）。
* 向量化原子操作：相比标量 16 位原子操作，理论性能提升接近 2 倍（32 位内存事务对 16 位数据的优势）。
