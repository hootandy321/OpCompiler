# 目录: InfiniTrain/tools 架构全景

## 1. 子系统职责

`InfiniTrain/tools` 目录作为训练工具子系统的容器，为分布式训练提供基础工具支持。该目录的核心职责是封装启动器、脚本和辅助程序，为训练流程提供便捷的进程管理、环境配置和任务调度功能。在 InfiniTrain 的整体架构中，该子系统作为用户入口和训练核心之间的桥梁，简化了分布式训练的复杂度，使开发者能够以统一的方式启动和管理训练任务。

## 2. 模块导航

* **infini_run**
    * *功能*: 轻量级的分布式训练进程管理工具，支持单节点和多节点环境下的并行训练启动
    * *职责*: 通过 fork 方式并行启动训练进程，自动配置分布式训练所需的环境变量（如进程排名、通信端点等），为上层训练程序提供标准化的分布式初始化接口

## 3. 架构逻辑图解

`InfiniTrain/tools` 子系统采用简洁的单模块设计，`infini_run` 作为核心组件承担所有功能职责。

**数据流与执行流程**：

1. **用户请求入口**：用户通过命令行调用 `infini_run`，传入节点配置（`nnodes`, `nproc_per_node`）、rendezvous 端点和训练程序路径

2. **配置解析阶段**：`infini_run` 解析命令行参数，计算全局进程总数（`world_size = nnodes * nproc_per_node`），并从 `rdzv_endpoint` 提取主节点地址和端口

3. **进程并行化阶段**：
   - 父进程通过 `fork()` 系统调用创建 `nproc_per_node` 个子进程
   - 每个子进程接收独立的环境变量配置，包括全局排名（`GLOBAL_PROC_RANK`）、本地排名（`LOCAL_PROC_RANK`）、节点信息（`NNODES`, `MASTER_ADDR`, `MASTER_PORT`）等

4. **训练执行阶段**：
   - 子进程通过 `execvp()` 替换为用户指定的训练程序
   - 训练程序读取环境变量，初始化分布式后端（如 NCCL、Gloo）
   - 所有进程通过 `MASTER_ADDR:MASTER_PORT` 建立通信连接

5. **同步与回收**：
   - 父进程通过 `wait()` 循环阻塞等待所有子进程完成
   - 确保所有训练进程退出后才释放资源，避免僵尸进程

**与 InfiniTrain 核心的关系**：

- `infini_run` 作为独立的启动器工具，不直接依赖 `infini_train` 核心库
- 它通过环境变量注入的方式，将分布式配置传递给训练程序
- 训练程序可以是基于 InfiniTrain 的任意实现，通过读取标准化的环境变量（`GLOBAL_PROC_RANK`, `PROC_WORLD_SIZE` 等）实现分布式初始化
- 这种解耦设计使得 `infini_run` 可以兼容不同的训练框架和实现

**典型使用场景的数据路径**：

- **单机多卡训练**：`--nnodes=1 --nproc_per_node=8` → 启动 8 个进程，每个进程对应一张 GPU 卡，通过共享内存或本地通信进行数据交换
- **多机多卡训练**：`--nnodes=4 --nproc_per_node=8` → 在 4 台机器上分别运行 `infini_run`，每台机器启动 8 个进程，全局 32 个进程通过 `rdzv_endpoint` 指定的主节点进行握手和同步
