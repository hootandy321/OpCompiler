# 测试目录架构全景

## 1. 子系统职责

本测试目录承担 InfiniLM 框架的多层次质量保障职责，涵盖三大核心测试场景：

- **性能基准测试**：对模型进行标准化的学术基准评估（C-Eval、MMLU），支持多硬件后端和多推理引擎的性能对比
- **Llama模型验证**：针对 Llama 架构进行端到端的正确性验证，包括推理输出对比、中间值校验以及完整的生成流程测试
- **Qwen3-MoE 组件测试**：针对混合专家模型的特定组件（注意力机制、MoE层）进行性能和正确性专项测试

该测试体系通过分层验证策略，从底层算子到完整推理链路，确保 InfiniLM 实现与 HuggingFace Transformers 的一致性，同时提供多硬件后端（CPU、CUDA、寒武纪、昇腾、Metax、Moore、天数、昆仑、海光）的性能基准数据。

## 2. 模块导航

* **bench (性能基准测试套件)**
    * *功能*：提供标准化的学术基准测试框架，支持 C-Eval（中国综合性评估）和 MMLU（大规模多任务语言理解）两大主流评测数据集
    * *职责*：评估模型在不同硬件后端和推理引擎（InfiniLM C++、PyTorch）下的准确率、吞吐量和延迟性能，支持离线缓存模式、多主题并行测试、结果CSV导出等功能

* **models/llama (Llama模型验证套件)**
    * *功能*：针对 Llama 架构提供完整的三层验证体系，包括前向传播验证、中间值粒度验证和端到端推理测试
    * *职责*：通过对比 InfiniLM 与 Transformers 的输出，验证模型实现的正确性；支持 Python/C++ 双后端、bfloat16/float32 双精度测试，以及包含 KV Cache 的预填充+解码多步推理流程验证

* **models/qwen3_moe (Qwen3-MoE组件测试套件)**
    * *功能*：对 Qwen3 混合专家模型的关键组件进行专项性能测试
    * *职责*：单独测试注意力模块（Qwen3MoeAttention）和 MoE 前馈网络（Qwen3MoeSparseMoeBlock）在预填充和解码阶段的表现，提供 TTFT（首字延迟）和吞吐量（tokens/s）性能指标

## 3. 架构逻辑图解

测试流程遵循分层验证策略，数据流和执行顺序如下：

```
┌─────────────────────────────────────────────────────────────┐
│                    测试入口层 (Entry Point)                  │
│  - bench/test_benchmark.py: 基准测试总控                     │
│  - models/*/test_*.py: 具体验证脚本                          │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│              模型加载与初始化层 (Model Setup)                 │
│  ┌─────────────┬─────────────┬─────────────────────────┐   │
│  │ 基准测试     │ Llama验证   │ Qwen3-MoE测试           │   │
│  │ InferEngine │ LlamaFor... │ 组件层加载              │   │
│  │ TorchBackend │ from_pretr  │ (Attention/MoE)        │   │
│  └─────────────┴─────────────┴─────────────────────────┘   │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│              测试执行层 (Test Execution)                     │
│  ┌─────────────────┬──────────────────┬─────────────────┐  │
│  │ 性能基准测试     │ 正确性验证       │ 组件性能测试     │  │
│  │ - C-Eval        │ - 推理输出对比   │ - Attention     │  │
│  │   (52科目)      │ - 中间值钩子     │   Prefill/Decode│  │
│  │ - MMLU          │ - 多步生成       │ - MoE           │  │
│  │   (57科目)      │ - 精度校验       │   吞吐量测试     │  │
│  └─────────────────┴──────────────────┴─────────────────┘  │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│              结果分析层 (Result Analysis)                    │
│  ┌─────────────────┬──────────────────┬─────────────────┐  │
│  │ 准确率统计       │ 数值差异分析      │ 性能指标收集    │  │
│  │ - 各科目准确率   │ - 逐张量对比     │ - 延迟测量      │  │
│  │ - 总体成绩       │ - 最大/平均差异  │ - 吞吐量计算    │  │
│  │                 │ - NaN/Inf检测    │ - 多硬件对比    │  │
│  └─────────────────┴──────────────────┴─────────────────┘  │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│              报告输出层 (Report Output)                      │
│  - 控制台实时输出：测试进度、中间结果、性能指标               │
│  - CSV导出：结构化数据（bench/test_benchmark.py）           │
│  - 详细诊断信息：错误定位、堆栈跟踪、张量统计                 │
└─────────────────────────────────────────────────────────────┘
```

### 测试模块间的协作关系

1. **基准测试模块 (bench/test_benchmark.py)**
   - 支持多后端切换（InfiniLM C++ vs PyTorch）
   - 统一的基准评估框架，兼容 C-Eval 和 MMLU 数据集格式
   - 离线缓存支持（`--cache_dir`），避免网络依赖
   - 设备映射抽象：支持 9 种硬件后端（CPU、NVIDIA、Cambricon、Ascend、Metax、Moore、Iluvatar、Kunlun、Hygon）

2. **Llama验证套件 (models/llama/)**
   - **test_forward_validation.py**：基础推理验证，对比单次前向传播的 logits 输出
   - **test_intermediate_validation.py**：深度诊断工具，通过 HookRegistry 捕获模型内部中间值（嵌入、RMSNorm、QKV投影、RoPE、注意力输出、MLP各阶段），逐层验证实现正确性
   - **test_llama_inference.py**：端到端生成测试，验证多轮预填充-解码流程
   - **utils.py**：共享工具库，提供张量转换（InfiniCore ↔ PyTorch）、数值对比、参数名规范化等功能

3. **Qwen3-MoE组件测试 (models/qwen3_moe/)**
   - **attention_test.py**：独立测试注意力模块，使用 Transformers 的 `Qwen3MoeAttention` 和 `Qwen3MoeRotaryEmbedding` 作为参考实现，测量预填充和解码阶段的 TTFT 和吞吐量
   - **moe_test.py**：独立测试 MoE 前馈层，加载 `Qwen3MoeSparseMoeBlock` 权重，验证混合专家路由和计算的正确性及性能

### 关键技术特性

- **多硬件后端抽象**：通过设备映射字典统一不同硬件的设备名称（如 "nvidia" → "cuda"）
- **KV Cache 支持**：InfiniLM C++ 后端内部管理缓存，Python 后端使用 `DynamicCache`
- **数值精度验证**：支持相对误差（rtol）和绝对误差（atol）双重容差配置，RoPE 操作使用放宽容差（5e-3）以适应 float32 精度差异
- **异常检测机制**：自动检测 NaN、Inf 值，并提供详细的张量统计信息（最小值、最大值、均值、标准差）
- **钩子系统**：通过 `_infinilm.HookRegistry` 和 PyTorch 的 `register_forward_hook` 捕获中间值，实现白盒测试
