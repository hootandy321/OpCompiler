# Clip Operation (Metax Backend) Core Implementation Documentation

Clip 操作的 Metax 后端实现，通过复用通用的逐元素运算框架实现对张量值的裁剪（将值限制在 [min, max] 区间内）。该实现利用 Moore Threads Metax GPU 的计算能力，支持 FP16、FP32、FP64 和 BF16 数据类型，并采用统一的逐元素运算内核调度机制。

## 1. Module Structure

- **`clip_metax.h`**: Clip 操作 Metax 后端的 API 声明，通过宏定义生成 Descriptor 类
- **`clip_metax.maca`**: Clip 操作 Metax 后端的实现，包含 Descriptor 类的具体创建和计算逻辑

## 2. Core Classes

### `Descriptor`
- **Location**: `clip_metax.h` (通过宏 `ELEMENTWISE_DESCRIPTOR` 生成)
- **Primary Function**: Clip 操作的描述符类，继承自 `InfiniopDescriptor`，负责管理操作所需的所有元数据、设备实现和工作空间大小
- **Key Members**:
  - `infiniDtype_t _dtype`: 操作的数据类型（FP16/FP32/FP64/BF16）
  - `op::elementwise::ElementwiseInfo _info`: 封装输入/输出张量的形状、步长、连续性等元数据
  - `std::unique_ptr<op::elementwise::metax::DeviceImpl> _device_info`: Metax 设备实现的智能指针
  - `size_t _workspace_size`: 内核执行所需的工作空间大小（字节）
- **Core Methods**:
  - `create(handle_, desc_ptr, out_desc, input_desc_vec)`: 静态工厂方法，验证参数并构造 Descriptor 实例
    - 验证数据类型支持（F16/F32/F64/BF16）
    - 验证输出与所有输入（input、min、max）的形状一致性
    - 通过 `CREATE_ELEMENTWISE_METAX_DESCRIPTOR` 宏初始化元数据和设备实现
    - 返回 `INFINI_STATUS_SUCCESS` 或相应的错误码
  - `calculate(workspace, workspace_size, output, inputs, stream)`: 执行 Clip 计算的核心方法
    - 检查工作空间大小是否充足
    - 根据 `_dtype` 分发到相应的模板特化：
      - `INFINI_DTYPE_F16`: 调用 `_device_info->calculate<256, cuda::ClipOp, half>(...)`
      - `INFINI_DTYPE_F32`: 调用 `_device_info->calculate<256, cuda::ClipOp, float>(...)`
      - `INFINI_DTYPE_F64`: 调用 `_device_info->calculate<256, cuda::ClipOp, double>(...)`
      - `INFINI_DTYPE_BF16`: 调用 `_device_info->calculate<256, cuda::ClipOp, cuda_bfloat16>(...)`
    - 实际计算由 `op::elementwise::metax::DeviceImpl` 执行
- **Lifecycle**:
  - **构造**: 通过 `create()` 静态方法构造，采用 RAII 模式管理资源
  - **析构**: 默认析构函数（`~Descriptor() = default;`），智能指针自动释放设备实现
  - **所有权**: Descriptor 拥有 `DeviceImpl` 的独占所有权（通过 `unique_ptr`）

### `cuda::ClipOp` (Functor)
- **Location**: `../cuda/kernel.cuh`
- **Primary Function**: Clip 操作的 CUDA 设备端仿函数，定义裁剪操作的语义
- **Key Members**:
  - `static constexpr size_t num_inputs = 3`: 声明需要 3 个输入（x、min、max）
- **Core Methods**:
  - `operator()(x, min_val, max_val)`: 设备端内联函数，执行裁剪操作
    - **对于 half2/cuda_bfloat162 类型**: 使用 `__hmax2(__hmin2(x, max_val), min_val)` 进行向量化裁剪（Moore Threads 平台）或逐元素 `std::clamp`（天数平台，通过 `ENABLE_ILUVATAR_API` 宏控制）
    - **对于其他类型**: 调用 `std::clamp(x, min_val, max_val)` 执行标量裁剪
    - 时间复杂度: O(1) per element
- **特性**: 支持向量化运算（2 个 FP16/BF16 元素打包），充分利用 GPU SIMD 能力

### `op::elementwise::metax::DeviceImpl`
- **Location**: `/home/qy/src/Infini/InfiniCore/src/infiniop/elementwise/metax/elementwise_metax.h`
- **Primary Function**: Metax 设备端的逐元素运算通用实现，封装内核启动逻辑和内存管理
- **Key Members**:
  - `std::shared_ptr<Opaque> _opaque`: 不透明指针，隐藏实现细节（Pimpl 模式）
- **Core Methods**:
  - `calculate<BLOCK_SIZE, Op, Tdata>(info, workspace, output, inputs, stream, args...)`: 单一数据类型版本的模板方法
    - `BLOCK_SIZE`: 线程块大小（Clip 操作使用 256）
    - `Op`: 操作类型（`cuda::ClipOp`）
    - `Tdata`: 数据类型（half/float/double/cuda_bfloat16）
    - 委托给内部 `Opaque::calculateImpl` 执行
  - `calculate<BLOCK_SIZE, Op, Tout, Tin...>(info, workspace, output, inputs, stream, args...)`: 多输入类型版本的模板方法（当前未使用）
- **内部实现 (`Opaque`)**:
  - `calculateImpl<BLOCK_SIZE, N, Op, Tdata>(...)`: 模板方法，调用 `launchElementwiseKernel` 启动内核
  - `infoToDevice<N>(...)`: 将主机端元数据（形状、步长、连续性标志）异步复制到设备内存
    - 计算元数据在 workspace 中的偏移量
    - 使用 `hcMemcpyAsync` 异步拷贝输入指针数组和元数据到设备
    - 内存布局: `[input_ptr_array][output_shape][output_strides][input_shapes][input_strides][input_contiguous][input_broadcasted]`
  - `launchElementwiseKernel<BLOCK_SIZE, N, KernelFunc, Tout>(...)`: 配置网格和线程块并启动内核
    - 处理空张量情况（output_size == 0 直接返回成功）
    - 动态计算网格维度：`gridDims.x = min(CEIL_DIV(output_size, blockDims.x), max_grid_size)`
    - 支持大张量分步执行（step = gridDims.x * blockDims.x）
    - 启动 `elementwiseKernel` CUDA 内核

### `op::elementwise::ElementwiseInfo`
- **Location**: `/home/qy/src/Infini/InfiniCore/src/infiniop/elementwise/elementwise.h`
- **Primary Function**: 封装逐元素运算所需的所有元数据，包括形状、步长、连续性和广播信息
- **Key Members**:
  - `std::vector<size_t> _meta`: 存储所有元数据的单一连续内存块（使用 size_t 数组以保证对齐）
  - `size_t _output_size`: 输出张量的元素总数
  - `size_t _input_size`: 输入张量的数量（Clip 操作为 3）
  - `size_t _ndim`: 张量的维度数
  - `bool _output_contiguous`: 输出张量是否内存连续
- **Core Methods**:
  - `create(output_desc, input_descs)`: 静态工厂方法，从张量描述符构造元数据
    - 验证输出不能有广播维度
    - 计算并分配元数据所需内存大小
    - 复制所有输入/输出的形状、步长、连续性标志
    - 返回 `Result<ElementwiseInfo>` 类型（可能包含错误状态）
  - 访问器方法（`getOutputSize()`, `getNdim()`, `getInputShape(index)`, `getInputStrides(index)` 等）：提供对元数据的只读访问
- **内存布局**（以 size_t 为单位的数组）:
  ```
  [output_shape (ndim)][output_strides (ndim)]
  [input_shapes (input_size * ndim)][input_strides (input_size * ndim)]
  [input_contiguous (input_size * bool, packed)][input_broadcasted (input_size * bool, packed)]
  ```

## 3. API Interface

### Public C API (Generated by Macro)

```cpp
namespace op::clip::metax {

class Descriptor final : public InfiniopDescriptor {
public:
    // 析构函数
    ~Descriptor();

    // 获取所需工作空间大小
    size_t workspaceSize() const;

    // 创建 Descriptor 实例
    static infiniStatus_t create(
        infiniopHandle_t handle,                  // Metax 设备句柄
        Descriptor **desc_ptr,                    // 输出：Descriptor 指针的指针
        infiniopTensorDescriptor_t output_desc,   // 输出张量描述符
        std::vector<infiniopTensorDescriptor_t> input_descs  // 输入张量描述符向量 [input, min, max]
    );

    // 执行 Clip 计算
    infiniStatus_t calculate(
        void *workspace,                          // 设备端工作空间指针
        size_t workspace_size,                    // 工作空间大小
        void *output,                             // 输出张量设备指针
        std::vector<const void *> inputs,         // 输入张量设备指针向量 [input, min, max]
        void *stream                              // Metax 计算流
    ) const;
};

}
```

### Internal Kernel Interface

```cuda
// 设备端内核函数 (定义于 elementwise_metax.h)
template <size_t N, typename Op, typename Tdata, typename... Args>
__global__ void elementwiseKernel(
    size_t output_size,              // 输出元素总数
    size_t ndim,                     // 张量维度数
    bool output_contiguous,          // 输出是否连续
    const bool *input_contiguous,    // 各输入是否连续 [N]
    const bool *input_broadcasted,   // 各输入是否广播 [N]
    const size_t *output_shape,      // 输出形状 [ndim]
    const size_t *input_shapes,      // 输入形状 [N * ndim]
    const ptrdiff_t *output_strides, // 输出步长 [ndim]
    const ptrdiff_t *input_strides,  // 输入步长 [N * ndim]
    Tdata *output,                   // 输出数据指针
    const void *const *inputs,       // 输入数据指针数组 [N]
    size_t offset,                   // 全局元素偏移量（用于大张量分步执行）
    Args... args                     // 额外参数（Clip 操作无）
);

// Clip 操作特化 (N=3, Op=ClipOp, Tdata=float/half/double/cuda_bfloat16)
// 执行: output[i] = clamp(input[i], min[i], max[i])
```

## 4. Usage Example

```cpp
// 示例：使用 Metax 后端执行 Clip 操作

#include "infiniop/ops/clip/metax/clip_metax.h"

void example_clip_metax(
    infiniopHandle_t handle,
    const float *d_input,   // 设备端输入张量 [N, C, H, W]
    const float *d_min,     // 设备端最小值张量（可与 input 广播）
    const float *d_max,     // 设备端最大值张量（可与 input 广播）
    float *d_output,        // 设备端输出张量
    std::vector<size_t> shape,  // 张量形状 {N, C, H, W}
    hcStream_t stream      // Metax 计算流
) {
    // 1. 创建张量描述符
    infiniopTensorDescriptor_t input_desc, min_desc, max_desc, output_desc;
    infoniopCreateTensorDescriptor(&input_desc, INFINI_DTYPE_F32, shape, /*strides=*/nullptr);
    infoniopCreateTensorDescriptor(&min_desc, INFINI_DTYPE_F32, {1}, /*strides=*/nullptr);  // 标量最小值
    infoniopCreateTensorDescriptor(&max_desc, INFINI_DTYPE_F32, {1}, /*strides=*/nullptr);  // 标量最大值
    infoniopCreateTensorDescriptor(&output_desc, INFINI_DTYPE_F32, shape, /*strides=*/nullptr);

    // 2. 创建 Clip 操作描述符
    op::clip::metax::Descriptor *clip_desc = nullptr;
    std::vector<infiniopTensorDescriptor_t> inputs = {input_desc, min_desc, max_desc};
    infiniStatus_t status = op::clip::metax::Descriptor::create(
        handle,
        &clip_desc,
        output_desc,
        inputs
    );
    if (status != INFINI_STATUS_SUCCESS) {
        // 处理错误（如类型不支持、形状不匹配等）
        return;
    }

    // 3. 分配工作空间
    size_t workspace_size = clip_desc->workspaceSize();
    void *d_workspace = nullptr;
    hcMalloc(&d_workspace, workspace_size);

    // 4. 执行 Clip 计算
    std::vector<const void *> input_ptrs = {d_input, d_min, d_max};
    status = clip_desc->calculate(
        d_workspace,
        workspace_size,
        d_output,
        input_ptrs,
        stream
    );

    // 5. 清理资源
    hcFree(d_workspace);
    delete clip_desc;
    infoniopDestroyTensorDescriptor(input_desc);
    infoniopDestroyTensorDescriptor(min_desc);
    infoniopDestroyTensorDescriptor(max_desc);
    infoniopDestroyTensorDescriptor(output_desc);

    // 结果: d_output[i] = clamp(d_input[i], d_min[0], d_max[0])
}
```

## 5. Implementation Details

- **Memory Management**:
  - **工作空间布局**: 工作空间分为两部分：输入指针数组（`input_size * sizeof(void*)`）+ 元数据（`ElementwiseInfo::getMetaMemSize()` 字节）
  - **设备内存传输**: 使用 `hcMemcpyAsync` 异步将元数据传输到设备，避免阻塞主机
  - **Pimpl 模式**: `DeviceImpl` 使用 `Opaque` 隐藏实现细节，减少编译依赖
  - **RAII**: 使用 `std::unique_ptr` 和 `std::shared_ptr` 自动管理资源生命周期

- **Concurrency**:
  - **异步执行**: 所有内核启动和内存拷贝都是异步的，通过 `hcStream_t` 流管理
  - **无共享状态**: Descriptor 实例在创建后不可变（immutable），多线程安全
  - **线程块大小**: 固定为 256 线程/块（`calculate<256, ...>`），平衡寄存器使用和占用率

- **Performance**:
  - **向量化指令**: FP16 和 BF16 类型使用 `half2` 和 `cuda_bfloat162` 打包，每个线程处理 2 个元素，理论吞吐量提升 2 倍
  - **连续性优化**: 对于连续内存张量，使用线性索引 `idx`；对于非连续张量，调用 `device::metax::indexToOffset` 进行多维度索引计算
  - **广播支持**: 自动处理形状广播（如将标量 min/max 广播到任意形状张量）
  - **大张量分步**: 当 `output_size > gridDims.x * blockDims.x` 时，内核自动分步执行，避免网格维度限制（Metax 设备最大 X 维网格大小限制）
  - **时间复杂度**: O(n)，n 为输出张量元素总数

- **Error Handling**:
  - **Result<T> 模式**: `ElementwiseInfo::create` 返回 `utils::Result<ElementwiseInfo>`，封装成功或错误状态
  - **宏辅助检查**: 使用 `CHECK_DTYPE`, `CHECK_SAME_SHAPE`, `CHECK_RESULT`, `CHECK_METAX` 等宏简化错误检查
  - **工作空间验证**: `calculate()` 方法首先验证 `workspace_size >= _workspace_size`，防止缓冲区溢出
  - **错误码**: 返回标准 `infiniStatus_t` 错误码（`INFINI_STATUS_SUCCESS`, `INFINI_STATUS_BAD_TENSOR_DTYPE`, `INFINI_STATUS_INSUFFICIENT_WORKSPACE` 等）

- **Dependencies**:
  - **外部依赖**: Moore Threads Metax Toolkit (`hcMemcpyAsync`, `hcStream_t`, `__global__` kernels)
  - **内部模块**:
    - `op::elementwise::metax::DeviceImpl`: 通用的逐元素运算设备实现
    - `op::elementwise::ElementwiseInfo`: 元数据管理结构
    - `device::metax::Handle`: Metax 设备句柄
    - `cuda::ClipOp`: CUDA 设备端裁剪操作仿函数（定义于 `../cuda/kernel.cuh`）
  - **C++ 标准库**: `std::vector`, `std::unique_ptr`, `std::shared_ptr`, `std::index_sequence`, `std::clamp` (C++17)

- **Design Patterns**:
  - **Macro-based Code Generation**: `ELEMENTWISE_DESCRIPTOR` 宏自动生成 Descriptor 类，减少重复代码
  - **Template Method Pattern**: `calculate()` 方法根据数据类型分发到不同的模板特化
  - **Strategy Pattern**: `DeviceImpl` 封装不同的内核启动策略（连续 vs 非连续，广播 vs 非广播）
  - **Factory Pattern**: `Descriptor::create()` 静态工厂方法负责对象构造和验证
  - **Pimpl (Pointer to Implementation)**: `DeviceImpl` 使用 `Opaque` 结构隐藏实现细节
  - **CRTP (Curiously Recurring Template Pattern)**: 通过模板参数 `Op` 将操作逻辑编译时绑定到内核

- **Hardware-Specific Optimizations**:
  - **Moore Threads Metax**: 使用 `hcStream_t` 而非 `cudaStream_t`，调用 `hcMemcpyAsync` 进行内存传输
  - **天数平台 (ILUVATAR)**: 当定义 `ENABLE_ILUVATAR_API` 宏时，`half2`/`cuda_bfloat162` 类型使用逐元素 `std::clamp` 而非 `__hmax2/__hmin2` 内置函数
  - **向量化加载**: FP16/BF16 使用 2 元素打包（`half2`/`cuda_bfloat162`），充分利用 GPU SIMD 单元
